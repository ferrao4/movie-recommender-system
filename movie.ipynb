{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139a3a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\merlin.f_servify\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import spacy\n",
    "import wordninja\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Load data\n",
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge data\n",
    "movies = movies.merge(credits, on='title')\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "\n",
    "# Convert columns\n",
    "def convert(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['name']) \n",
    "    return L\n",
    "\n",
    "movies.dropna(inplace=True)\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "def convert_cast(text):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    if isinstance(text, list):\n",
    "        for i in text:\n",
    "            if counter < 3:\n",
    "                L.append(i)\n",
    "                counter += 1\n",
    "    return L\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert_cast)\n",
    "movies['cast'] = movies['cast'].apply(lambda x: x[0:3])\n",
    "\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "    return L \n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "def collapse(L):\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \",\"\"))\n",
    "    return L1\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(collapse)\n",
    "movies['genres'] = movies['genres'].apply(collapse)\n",
    "movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "new = movies.drop(columns=['overview', 'genres', 'keywords', 'cast', 'crew'])\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Text cleaning and preprocessing\n",
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', '', text)\n",
    "\n",
    "new['tags'] = new['tags'].apply(clean_text)\n",
    "\n",
    "def reinsert_spaces(text):\n",
    "    text = re.sub(r'(?<!^)(?<!\\s)(?<!\\d)(?<![a-z])(?=[A-Z])', ' ', text)\n",
    "    pattern = '|'.join(f'(?<!\\w){word}(?!\\w)' for word in common_words)\n",
    "    text = re.sub(pattern, r' \\0 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "common_words = ['the', 'and', 'a', 'in', 'of', 'to', 'is', 'with', 'on', 'for', 'when', 'who', 'which', 'where', 'how', 'why', 'as', 'it', 'at', 'an', 'by', 'or', 'from', 'that', 'this', 'but', 'was', 'has', 'been', 'will', 'shall', 'may', 'could', 'would', 'might', 'can']\n",
    "new['tags'] = new['tags'].apply(reinsert_spaces)\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "tfidf_vector = tfidf.fit_transform(new['tags']).toarray()\n",
    "\n",
    "# Matrix factorization with SVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "svd_matrix = svd.fit_transform(tfidf_vector)\n",
    "svd_similarity = cosine_similarity(svd_matrix)\n",
    "\n",
    "# Recommendation Functions\n",
    "def recommend(movie):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(svd_similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    for i in distances[1:6]:\n",
    "        print(new.iloc[i[0]].title)\n",
    "\n",
    "def hybrid_recommend(movie, alpha=0.5):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    content_distances = sorted(list(enumerate(svd_similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    collab_distances = sorted(list(enumerate(svd_similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    combined_scores = {}\n",
    "    for i, score in content_distances[1:]:\n",
    "        combined_scores[i] = combined_scores.get(i, 0) + alpha * score\n",
    "    for i, score in collab_distances[1:]:\n",
    "        combined_scores[i] = combined_scores.get(i, 0) + (1 - alpha) * score\n",
    "    sorted_scores = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i in sorted_scores[:5]:\n",
    "        print(new.iloc[i[0]].title)\n",
    "\n",
    "# Flask API\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/recommend', methods=['GET'])\n",
    "def recommend_route():\n",
    "    movie = request.args.get('movie')\n",
    "    if movie in new['title'].values:\n",
    "        recommendations = recommend(movie)\n",
    "        return jsonify({'recommendations': recommendations})\n",
    "    else:\n",
    "        return jsonify({'error': 'Movie not found'}), 404\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(svd, 'svd_model.pkl')\n",
    "\n",
    "print(\"Models saved and server started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d29e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
